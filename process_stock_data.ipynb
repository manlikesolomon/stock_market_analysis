{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397ee3f8",
   "metadata": {},
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "134f13fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/homebrew/Cellar/apache-spark/4.0.0/libexec'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import Window\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ade59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/28 20:43:17 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/28 20:43:36 ERROR Utils: Uncaught exception in thread driver-heartbeater\n",
      "java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.executor.ProcfsMetricsGetter$\n",
      "\tat org.apache.spark.metrics.ProcessTreeMetrics$.getMetricValues(ExecutorMetricType.scala:94)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.$anonfun$getCurrentMetrics$1(ExecutorMetrics.scala:103)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.$anonfun$getCurrentMetrics$1$adapted(ExecutorMetrics.scala:102)\n",
      "\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.getCurrentMetrics(ExecutorMetrics.scala:102)\n",
      "\tat org.apache.spark.SparkContext.reportHeartBeat(SparkContext.scala:2952)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$25(SparkContext.scala:615)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NullPointerException [in thread \"executor-heartbeater\"]\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter.isProcfsAvailable$lzycompute(ProcfsMetricsGetter.scala:62)\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter.isProcfsAvailable(ProcfsMetricsGetter.scala:51)\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter.<init>(ProcfsMetricsGetter.scala:48)\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter$.<clinit>(ProcfsMetricsGetter.scala:162)\n",
      "\tat org.apache.spark.metrics.ProcessTreeMetrics$.getMetricValues(ExecutorMetricType.scala:94)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.$anonfun$getCurrentMetrics$1(ExecutorMetrics.scala:103)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.$anonfun$getCurrentMetrics$1$adapted(ExecutorMetrics.scala:102)\n",
      "\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.getCurrentMetrics(ExecutorMetrics.scala:102)\n",
      "\tat org.apache.spark.executor.ExecutorMetricsPoller.poll(ExecutorMetricsPoller.scala:82)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1269)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\t... 9 more\n",
      "25/07/28 20:43:37 ERROR Utils: Uncaught exception in thread executor-heartbeater\n",
      "java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.executor.ProcfsMetricsGetter$\n",
      "\tat org.apache.spark.metrics.ProcessTreeMetrics$.getMetricValues(ExecutorMetricType.scala:94)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.$anonfun$getCurrentMetrics$1(ExecutorMetrics.scala:103)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.$anonfun$getCurrentMetrics$1$adapted(ExecutorMetrics.scala:102)\n",
      "\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\n",
      "\tat org.apache.spark.executor.ExecutorMetrics$.getCurrentMetrics(ExecutorMetrics.scala:102)\n",
      "\tat org.apache.spark.executor.ExecutorMetricsPoller.poll(ExecutorMetricsPoller.scala:82)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1269)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NullPointerException [in thread \"executor-heartbeater\"]\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter.isProcfsAvailable$lzycompute(ProcfsMetricsGetter.scala:62)\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter.isProcfsAvailable(ProcfsMetricsGetter.scala:51)\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter.<init>(ProcfsMetricsGetter.scala:48)\n",
      "\tat org.apache.spark.executor.ProcfsMetricsGetter$.<clinit>(ProcfsMetricsGetter.scala:162)\n",
      "\t... 17 more\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder \\\n",
    "    .appName(\"DeltaLake4App\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f870a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.1.16:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DeltaLake4App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12d7f0550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c10eaa",
   "metadata": {},
   "source": [
    "## Get and Process Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "067fb029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/kdtrw_0n6t1cplgyjkc4hwx00000gr/T/ipykernel_19116/2246109638.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  raw = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')\n",
      "[*********************100%***********************]  30 of 30 completed\n"
     ]
    }
   ],
   "source": [
    "# Get yesterday's date\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "end_date = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Get start date (3 years before yesterday)\n",
    "start_date = (yesterday - timedelta(days=3*365)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"NVDA\", \"GOOGL\", \"AMZN\", \"META\", \"AVGO\", \"BRK-B\", \"TSLA\", \"TSM\",\n",
    "    \"JPM\", \"WMT\", \"LLY\", \"ORCL\", \"V\", \"MA\", \"NFLX\", \"XOM\", \"COST\", \"JNJ\",\n",
    "    \"ABBV\", \"SAP\", \"BABA\", \"GS\", \"HD\", \"VRTX\", \"UNH\", \"MRK\", \"PEP\", \"TMO\"\n",
    "]\n",
    "\n",
    "# Download stock data\n",
    "raw = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817e92f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>115.099998</td>\n",
       "      <td>116.250000</td>\n",
       "      <td>112.430000</td>\n",
       "      <td>113.669998</td>\n",
       "      <td>42339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>12.433765</td>\n",
       "      <td>12.485706</td>\n",
       "      <td>11.932339</td>\n",
       "      <td>12.206026</td>\n",
       "      <td>532763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>251.839996</td>\n",
       "      <td>257.739990</td>\n",
       "      <td>241.360001</td>\n",
       "      <td>252.309998</td>\n",
       "      <td>128948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>V</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>282.515735</td>\n",
       "      <td>284.505283</td>\n",
       "      <td>279.998959</td>\n",
       "      <td>283.878571</td>\n",
       "      <td>4160800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>163.517909</td>\n",
       "      <td>165.169911</td>\n",
       "      <td>159.477484</td>\n",
       "      <td>161.000107</td>\n",
       "      <td>19699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14955</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>155.159831</td>\n",
       "      <td>155.764646</td>\n",
       "      <td>153.018187</td>\n",
       "      <td>154.059265</td>\n",
       "      <td>9099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>LLY</td>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>774.933279</td>\n",
       "      <td>785.035142</td>\n",
       "      <td>769.523717</td>\n",
       "      <td>775.690430</td>\n",
       "      <td>3924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8080</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>219.989947</td>\n",
       "      <td>222.538583</td>\n",
       "      <td>219.143679</td>\n",
       "      <td>219.379852</td>\n",
       "      <td>6923500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13441</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>108.867318</td>\n",
       "      <td>109.818556</td>\n",
       "      <td>102.882439</td>\n",
       "      <td>103.387779</td>\n",
       "      <td>30841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22393</th>\n",
       "      <td>TMO</td>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>538.506028</td>\n",
       "      <td>550.353714</td>\n",
       "      <td>537.268368</td>\n",
       "      <td>544.624512</td>\n",
       "      <td>1839300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price Ticker       Date        Open        High         Low       Close  \\\n",
       "3055    AMZN 2022-10-10  115.099998  116.250000  112.430000  113.669998   \n",
       "1546    NVDA 2022-09-29   12.433765   12.485706   11.932339   12.206026   \n",
       "6687    TSLA 2025-04-11  251.839996  257.739990  241.360001  252.309998   \n",
       "11048      V 2024-09-12  282.515735  284.505283  279.998959  283.878571   \n",
       "2778   GOOGL 2024-08-29  163.517909  165.169911  159.477484  161.000107   \n",
       "14955    JNJ 2025-04-23  155.159831  155.764646  153.018187  154.059265   \n",
       "9613     LLY 2024-12-17  774.933279  785.035142  769.523717  775.690430   \n",
       "8080     JPM 2024-11-01  219.989947  222.538583  219.143679  219.379852   \n",
       "13441    XOM 2025-04-04  108.867318  109.818556  102.882439  103.387779   \n",
       "22393    TMO 2025-01-07  538.506028  550.353714  537.268368  544.624512   \n",
       "\n",
       "Price     Volume  \n",
       "3055    42339700  \n",
       "1546   532763000  \n",
       "6687   128948100  \n",
       "11048    4160800  \n",
       "2778    19699800  \n",
       "14955    9099400  \n",
       "9613     3924800  \n",
       "8080     6923500  \n",
       "13441   30841300  \n",
       "22393    1839300  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert multi-index DataFrame to flat DataFrame\n",
    "df_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    ticker_df = raw[ticker].reset_index()\n",
    "    ticker_df['Ticker'] = ticker\n",
    "    df_list.append(ticker_df)\n",
    "\n",
    "flat_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# reorder columns \n",
    "cols = ['Ticker', 'Date'] + [col for col in flat_df.columns if col not in ['Ticker', 'Date']]\n",
    "flat_df = flat_df[cols]\n",
    "\n",
    "flat_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4001372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticker: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store data in a spark dataframe\n",
    "spark_df = spark.createDataFrame(flat_df)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16f189",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36678ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate daily returns\n",
    "window_spec = Window.partitionBy('Ticker').orderBy('Date')\n",
    "\n",
    "spark_df = spark_df.withColumn('Prev_close', lag('Close').over(window_spec))\n",
    "\n",
    "spark_df = spark_df.withColumn(\n",
    "    'Daily_return',\n",
    "    round(((col('Close') - col('Prev_close')) / col('Prev_close') * 100), 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43fc41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate daily volutility rate \n",
    "spark_df = spark_df.withColumn(\n",
    "    'Volatility',\n",
    "    round(((col('High') - col('Low')) / col('Low') * 100), 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4afdb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
